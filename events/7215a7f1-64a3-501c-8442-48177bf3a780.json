{
  "id": 3181,
  "guid": "7215a7f1-64a3-501c-8442-48177bf3a780",
  "logo": "",
  "date": "2019-12-29T11:45:00+01:00",
  "start": "11:45",
  "duration": "00:05",
  "room": "Borg",
  "slug": "BWNUSE",
  "url": "https://c3lt.de/36c3/talk/BWNUSE/",
  "title": "Hacking Neural Networks",
  "subtitle": "",
  "track": "#36C3 Lightning Talks",
  "type": "Lightning Talk",
  "language": "en",
  "abstract": "A quick look at one of many vulnerabilities deep learning can have and how you can learn more about exploiting and defending neural networks.",
  "description": "Neural networks are all the rage, but how secure are they? In this talk, I will show you that there is nothing magical about neurons and how they are as susceptible to hacking as any other piece of software.  Together, we will explore one such vulnerability, which is part of the open source course \"Hacking Neural Networks: A Short Introduction\" that I made available on GitHub: https://github.com/Kayzaks/HackingNeuralNetworks",
  "recording_license": "",
  "do_not_record": false,
  "persons": [
    {
      "id": 149,
      "code": "JRJMTF",
      "public_name": "Michael Kissner",
      "biography": null,
      "answers": []
    }
  ],
  "links": [],
  "attachments": [],
  "answers": []
}